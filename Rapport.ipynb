{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Machine Learning : Xente Fraud Detection\n",
    "Auteurs : Théo Engels, Hadrien Godts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline as skPipeline\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from CustomTransformers import StringCleanTransformer, DayTimeTransformer, DropperTransformer, SignTransformer, OHTransformer, FloatTransformer, biningTransformer, weekdayTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Ce rapport présente les processus et les résultats de notre travail sur le Xente fraud detection challenge. Nous commençons par une analyse des données présentes dans le dataset, suivie de la hase de feature engineering. Nous présentons ensuite les différents modèles que nous avons entrainés et leurs performances, et nous terminons par une courte conclusion et quelques perspectives de recherche.\n",
    "\n",
    "L’objectif de ce challenge est de prédire si une transaction bancaire est frauduleuse ou pas, sur la base des différents features contenus dans le dataset.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des données\n",
    "\n",
    "La première chose importante à noter est que le training set contient 95 662 entrées, parmi lesquelles on compte 95 469 transactions légales et 193 frauduleuses : c’est un déséquilibre fort et important à noter car le manque de transactions frauduleuses risque de compliquer l’entrainement des modèles. Nous pallions cette faiblesse dans le feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour nbr transactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La seconde chose importante à propos des données est qu’il ne manque aucune donnée : toutes les entrées ont des données pour chaque feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour données manquantes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons ensuite les différents feature du dataset. S’il y a des choses importantes, nous les mentionnons ici.\n",
    "-\tTransactionId : numéro de la transaction. Cette donnée est à garder car elle permet de soumettre les résultats au défi, mais nous retirerons cette colonne du dataset dans la mesure où le numéro de la transaction ne devrait rien nous apprendre de particulier sur son caractère frauduleux.\n",
    "-\tBatchId : le numéro de groupe de transaction. Comme pour le numéro de transaction, cette donnée ne devrait rien nous apprendre sur le caractère frauduleux d’une transaction. Par ailleurs, dans l’hypothèse improbable où toutes les transactions sont regroupées dans le même groupe, nous ferions face à du target leakage puisque le numéro de Batch nous dirait directement quelque chose à propos de la légalité de la transacition.\n",
    "-\tAccountId : l’identifiant d’un compte client. Nous conservons cette donnée.\n",
    "-\tSubscriptionId : l’identifiant d’une souscription. D’après la description des features, cette donnée semble liée à un compte client, sans autre explication particulièrement révélatrice. Vu ce lien et ce manque de clarté, nous décidons de laisser cette variable hors du dataset, afin d’en réduire la taille.\n",
    "-\tCustomerId : l’identifiant d’un client. À priori, un client peut disposer de plusieurs comptes, donc pour réduire la taille du dataset, nous laissons cette variable hors du dataset en privilégiant AccountId. Cela étant, si on peut établir qu’un compte fraude plus que les autres, il sera pertinent de reconstruire le lien vers le CustomerId.\n",
    "-\tCurrencyCode : la monnaie de la transaction. Il n’y a qu’une seule valeur pour ce feature, donc nous le laissons également hors du dataset.\n",
    "-\tCountryCode : le code du pays de la transaction. Idem que CurrencyCode, nous le laissons donc également hors du dataset.\n",
    "-\tProviderId KEEP : indique la source du produit acheté via la transaction. Nous conservons cette feature en faisant un one-hot encoding sur les six valeurs possibles, en partant du principe qu'il peut y avoir un lien entre la source du produit et le caractère frauduleux de la transaction.\n",
    "-\tProductId : donne le code du produit qui a été acheté lors de la transaction. Cette colonne contient 23 valeurs possibles et ne se prête donc pas à du one-hot encoding. En outre, nous disposons de la variable ProductCategory (voir ci-après) donc nous décidons de laisser celle-ci hors du dataset. \n",
    "-\tProductCategory : indique la catégorie de produit qui a été fait l’objet de la transaction. Il y a 9 catégories possibles, donc nous pouvons faire du one-hot encoding pour conserver cette feature.\n",
    "-\tChannelId : indique la méthode de paiement utilisée pour effectuer la transaction. Cette feature nous semble importante, nous la conservons donc en faisant du one-hot encoding une fois de plus.\n",
    "-\tAmount : indique le montant de la transaction, avec son signe (+ ou - pour crédit ou débit). La feature value nous donne déjà le montant absolu, donc nous faisons donc d'abord du binary encoding pour que les montant positif soient désormais true, et les montant négatifs false.\n",
    "-\tValue : indique le montant de la transaction, sans son signe. Nous conservons cette feature.\n",
    "-\tTransactionStartTime : indique la date et l'horaire de la transaction. Nous convertissons le format de cette donnée pour avoir un ordre chronologique, puis nous la séparons en une colonne date et une colonne heure. La colonne date est convertie pour avoir le jour de la semaine et one-hot encodée ensuite. La colonne heure laissée telle quelle pour le moment.\n",
    "-\tPricingStrategy : indique la strucure de prix de Xente pour ses différents marchands. Sans certitude sur ce que cette colonne représente exactement, nous la one-hot encodons et verrons par la suite si elle a un impact ou non.\n",
    "-\tFraudResult : indique si la transaction est frauduleuse. Il s’agit de notre target, nous la gardons donc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour nunique"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Le dataset est déjà séparé en training et en validation, ce qui nous épargne cette étape. Afin d’organiser efficacement notre travail, nous rédigeons le code sous forme de pipelines.\n",
    "\n",
    "Nous créons deux préprocesseurs : le premier pour la transformation des données, et le second pour un échantillonnage artificiel. Ce dernier ne peut pas être appliqué au validation set, cela créerait du data leakage – mais il faut toutefois transformer ces données, d’où l’intérêt de séparer les deux préprocesseurs.\n",
    "Les transformations du premier préprocesseur sont décrites dans le tableau suivant :\n",
    "\n",
    "| Transformateur | Description |\n",
    "| --- | --- |\n",
    "| shuffle | Randomise l’ordre des entrées dans le dataset. |\n",
    "| remove_target | Retire la colonne « transaction_id » en la sauvegardant pour poster les données sur le site web. Cette étape doit se faire après le shuffle pour que les prédictions soient dans le même ordre que les numéros de transaction. |\n",
    "| clean_strings | Pour les colonnes qui ont un id précédé d'un string (par exemple : BatchID_578), retire le texte en ne conserve que le numéro |\n",
    "| refactor_daytime | Convertit le format de TransactionStartTime en format yyyymmddhhmmss. |\n",
    "| drop | Supprime les features marqués comme non-pertinents (voir analyse des données) |\n",
    "| convert_amount | Remplace les valeurs de la colonne amount par true si elles sont positives et false si elles sont négatives ; la colonne est renommée « sign ». |\n",
    "| one_hot_encode | Effectue un one-hot-encoding pour les colonnes suivantes : ProviderId, ProductCategory, ChannelId, PricingStrategy et Sign. |\t\n",
    "| bin |  | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour le preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles\n",
    "Nous entrainons les données adaptées sur trois modèles : un Random Forest, un XGBoost et un MLP ; le tableau Y montre les performances de ces modèles, sans adaptation particulière de leurs paramètres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour le modèle de base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont les suivants :\n",
    "\n",
    "| Modèle | Public score | Private score |\n",
    "| --- | --- | --- |\n",
    "| Random Forest | 0.9994 | 0.9994 |\n",
    "| XGBoost | 0.75 | 0.73 |\n",
    "| MLP | 0.9994 | 0.9994 |\n",
    "\n",
    "![Random Forest Result]()\n",
    "![XGBoost Result]()\n",
    "![MLP Result]()\n",
    "\n",
    "Nous voyons clairement que le XGBoost présente les meilleurs résultats. Nous nous tentons donc de partir de cette base pour améliorer encore le modèle. Nous travaillons principalement sur les paramètres suivants  :\n",
    "-\tLe type de booster\n",
    "-\tn_estimators\n",
    "-\tlearning rate\n",
    "-\tmax_depth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour le modèle avec paramètres améliorés"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici les résultats obtenus :\n",
    "\n",
    "| Adaptation | Public score | Private score |\n",
    "| --- | --- | --- |\n",
    "\n",
    "\n",
    "Par ailleurs, nous faisons les essais suivants :\n",
    "-\tEffectuer l’échantillonnage artificiel avant le feature engineering dans le training set\n",
    "-\tConserver le feature « ProductId »"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour le modèle final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion et perspectives\n",
    "[Conclusion]\n",
    "\n",
    "Le score obtenu nous semble satisfaisant, d'autant plus qu'il nous place parmi les 128 meilleurs scores du concours, mais nous pensons qu’il est possible de l’améliorer encore. Nous avons plusieurs pistes pour y parvenir :\n",
    "-\tFaire du binning sur l'heure pour avoir matin - journée - soir au lieu de l'heure exacte.\n",
    "\n",
    "-\tL1 & L2\n",
    "-\tsubsample\n",
    "-\tmin_child_weight\n",
    "-\tgamma\n",
    "\n",
    "-\tFaire davantage de feature engineering avec davantage de domaine knowledge. Au regard des résultats obtenus par les participants au concours, il doit y avoir une manipulation de données qui permet d'améliorer nettement le score, mais à ce stade-ci nous manquons probablement de connaissances spécifiques pour la trouver.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
