{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Machine Learning : Xente Fraud Detection\n",
    "Auteurs : Théo Engels, Hadrien Godts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline as skPipeline\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from CustomTransformers import StringCleanTransformer, DayTimeTransformer, DropperTransformer, SignTransformer, OHTransformer, FloatTransformer, biningTransformer, weekdayTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/training.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "train_Y = train.FraudResult\n",
    "train.drop(['FraudResult'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "StringToClean = [\"TransactionId\", \"BatchId\",\"AccountId\",\"SubscriptionId\",\"CustomerId\", \"ProviderId\", \"ProductId\", \"ChannelId\", \"ProductCategory\"]\n",
    "\n",
    "drop_cols = [\"CurrencyCode\", \"BatchId\", \"CountryCode\", \"CustomerId\", \"PricingStrategy\", \"Amount\"]\n",
    "hot_cols = [\"ProductCategory\"]\n",
    "bin_cols = [\"TransactionStartTime\"]\n",
    "smt  = SMOTE()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Ce rapport présente les processus et les résultats de notre travail sur le Xente fraud detection challenge. Nous commençons par une analyse des données présentes dans le dataset, suivie de la hase de feature engineering. Nous présentons ensuite les différents modèles que nous avons entrainés et leurs performances, et nous terminons par une courte conclusion et quelques perspectives de recherche.\n",
    "\n",
    "L’objectif de ce challenge est de prédire si une transaction bancaire est frauduleuse ou pas, sur la base des différents features contenus dans le dataset.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des données\n",
    "\n",
    "La première chose importante à noter est que le training set contient 95 662 entrées, parmi lesquelles on compte 95 469 transactions légales et 193 frauduleuses : c’est un déséquilibre fort et important à noter car le manque de transactions frauduleuses risque de compliquer l’entrainement des modèles. Nous pallions cette faiblesse dans le feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb de transactions :  95662\n",
      "Nb de fraudes :  193\n",
      "Nb de non fraudes :  95469\n",
      "ratio fraudes/non frondes :  0.0020215986341115964\n"
     ]
    }
   ],
   "source": [
    "# Code pour nbr transactions\n",
    "print(\"Nb de transactions : \",train_Y.count())\n",
    "print(\"Nb de fraudes : \",train_Y.value_counts()[1])\n",
    "print(\"Nb de non fraudes : \",train_Y.value_counts()[0])\n",
    "print(\"ratio fraudes/non frondes : \",train_Y.value_counts()[1] / train_Y.value_counts()[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La seconde chose importante à propos des données est qu’il ne manque aucune donnée : toutes les entrées ont des données pour chaque feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are there missing values :  False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionId</th>\n",
       "      <th>BatchId</th>\n",
       "      <th>AccountId</th>\n",
       "      <th>SubscriptionId</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CurrencyCode</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>ProviderId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ChannelId</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Value</th>\n",
       "      <th>TransactionStartTime</th>\n",
       "      <th>PricingStrategy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TransactionId_28668</td>\n",
       "      <td>BatchId_27987</td>\n",
       "      <td>AccountId_846</td>\n",
       "      <td>SubscriptionId_3540</td>\n",
       "      <td>CustomerId_1192</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_1</td>\n",
       "      <td>ProductId_10</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>7000</td>\n",
       "      <td>2019-02-09T08:24:30Z</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TransactionId_55911</td>\n",
       "      <td>BatchId_64494</td>\n",
       "      <td>AccountId_318</td>\n",
       "      <td>SubscriptionId_3087</td>\n",
       "      <td>CustomerId_647</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_3</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2018-12-19T19:52:27Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TransactionId_42354</td>\n",
       "      <td>BatchId_103410</td>\n",
       "      <td>AccountId_1825</td>\n",
       "      <td>SubscriptionId_4080</td>\n",
       "      <td>CustomerId_2216</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_3</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2018-12-16T10:32:37Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TransactionId_69642</td>\n",
       "      <td>BatchId_108435</td>\n",
       "      <td>AccountId_3274</td>\n",
       "      <td>SubscriptionId_665</td>\n",
       "      <td>CustomerId_3703</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_1</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>2019-02-08T15:42:00Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TransactionId_44669</td>\n",
       "      <td>BatchId_137885</td>\n",
       "      <td>AccountId_2402</td>\n",
       "      <td>SubscriptionId_1884</td>\n",
       "      <td>CustomerId_2816</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_5</td>\n",
       "      <td>ProductId_10</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>2018-12-25T10:14:51Z</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TransactionId         BatchId       AccountId       SubscriptionId  \\\n",
       "0  TransactionId_28668   BatchId_27987   AccountId_846  SubscriptionId_3540   \n",
       "1  TransactionId_55911   BatchId_64494   AccountId_318  SubscriptionId_3087   \n",
       "2  TransactionId_42354  BatchId_103410  AccountId_1825  SubscriptionId_4080   \n",
       "3  TransactionId_69642  BatchId_108435  AccountId_3274   SubscriptionId_665   \n",
       "4  TransactionId_44669  BatchId_137885  AccountId_2402  SubscriptionId_1884   \n",
       "\n",
       "        CustomerId CurrencyCode  CountryCode    ProviderId     ProductId  \\\n",
       "0  CustomerId_1192          UGX          256  ProviderId_1  ProductId_10   \n",
       "1   CustomerId_647          UGX          256  ProviderId_6   ProductId_3   \n",
       "2  CustomerId_2216          UGX          256  ProviderId_6   ProductId_3   \n",
       "3  CustomerId_3703          UGX          256  ProviderId_6   ProductId_1   \n",
       "4  CustomerId_2816          UGX          256  ProviderId_5  ProductId_10   \n",
       "\n",
       "  ProductCategory    ChannelId   Amount  Value  TransactionStartTime  \\\n",
       "0         airtime  ChannelId_3   7000.0   7000  2019-02-09T08:24:30Z   \n",
       "1         airtime  ChannelId_3   1000.0   1000  2018-12-19T19:52:27Z   \n",
       "2         airtime  ChannelId_3   1000.0   1000  2018-12-16T10:32:37Z   \n",
       "3         airtime  ChannelId_3  10000.0  10000  2019-02-08T15:42:00Z   \n",
       "4         airtime  ChannelId_3   5000.0   5000  2018-12-25T10:14:51Z   \n",
       "\n",
       "   PricingStrategy  \n",
       "0                4  \n",
       "1                2  \n",
       "2                2  \n",
       "3                2  \n",
       "4                4  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code pour données manquantes\n",
    "\n",
    "print(\"are there missing values : \", train.isnull().values.any())\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons ensuite les différents feature du dataset. S’il y a des choses importantes, nous les mentionnons ici.\n",
    "-\tTransactionId : numéro de la transaction. Cette donnée est à garder car elle permet de soumettre les résultats au défi, mais nous retirerons cette colonne du dataset dans la mesure où le numéro de la transaction ne devrait rien nous apprendre de particulier sur son caractère frauduleux.\n",
    "-\tBatchId : le numéro de groupe de transaction. Comme pour le numéro de transaction, cette donnée ne devrait rien nous apprendre sur le caractère frauduleux d’une transaction. Par ailleurs, dans l’hypothèse improbable où toutes les transactions sont regroupées dans le même groupe, nous ferions face à du target leakage puisque le numéro de Batch nous dirait directement quelque chose à propos de la légalité de la transacition.\n",
    "-\tAccountId : l’identifiant d’un compte client. Nous conservons cette donnée.\n",
    "-\tSubscriptionId : l’identifiant d’une souscription. D’après la description des features, cette donnée semble liée à un compte client, sans autre explication particulièrement révélatrice. Vu ce lien et ce manque de clarté, nous décidons de laisser cette variable hors du dataset, afin d’en réduire la taille.\n",
    "-\tCustomerId : l’identifiant d’un client. À priori, un client peut disposer de plusieurs comptes, donc pour réduire la taille du dataset, nous laissons cette variable hors du dataset en privilégiant AccountId. Cela étant, si on peut établir qu’un compte fraude plus que les autres, il sera pertinent de reconstruire le lien vers le CustomerId.\n",
    "-\tCurrencyCode : la monnaie de la transaction. Il n’y a qu’une seule valeur pour ce feature, donc nous le laissons également hors du dataset.\n",
    "-\tCountryCode : le code du pays de la transaction. Idem que CurrencyCode, nous le laissons donc également hors du dataset.\n",
    "-\tProviderId KEEP : indique la source du produit acheté via la transaction. Nous conservons cette feature en faisant un one-hot encoding sur les six valeurs possibles, en partant du principe qu'il peut y avoir un lien entre la source du produit et le caractère frauduleux de la transaction.\n",
    "-\tProductId : donne le code du produit qui a été acheté lors de la transaction. Cette colonne contient 23 valeurs possibles et ne se prête donc pas à du one-hot encoding. En outre, nous disposons de la variable ProductCategory (voir ci-après) donc nous décidons de laisser celle-ci hors du dataset. \n",
    "-\tProductCategory : indique la catégorie de produit qui a été fait l’objet de la transaction. Il y a 9 catégories possibles, donc nous pouvons faire du one-hot encoding pour conserver cette feature.\n",
    "-\tChannelId : indique la méthode de paiement utilisée pour effectuer la transaction. Cette feature nous semble importante, nous la conservons donc en faisant du one-hot encoding une fois de plus.\n",
    "-\tAmount : indique le montant de la transaction, avec son signe (+ ou - pour crédit ou débit). La feature value nous donne déjà le montant absolu, donc nous faisons donc d'abord du binary encoding pour que les montant positif soient désormais true, et les montant négatifs false.\n",
    "-\tValue : indique le montant de la transaction, sans son signe. Nous conservons cette feature.\n",
    "-\tTransactionStartTime : indique la date et l'horaire de la transaction. Nous convertissons le format de cette donnée pour avoir un ordre chronologique, puis nous la séparons en une colonne date et une colonne heure. La colonne date est convertie pour avoir le jour de la semaine et one-hot encodée ensuite. La colonne heure laissée telle quelle pour le moment.\n",
    "-\tPricingStrategy : indique la strucure de prix de Xente pour ses différents marchands. Sans certitude sur ce que cette colonne représente exactement, nous la one-hot encodons et verrons par la suite si elle a un impact ou non.\n",
    "-\tFraudResult : indique si la transaction est frauduleuse. Il s’agit de notre target, nous la gardons donc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique :\n",
      " TransactionId           95662\n",
      "BatchId                 94809\n",
      "AccountId                3633\n",
      "SubscriptionId           3627\n",
      "CustomerId               3742\n",
      "CurrencyCode                1\n",
      "CountryCode                 1\n",
      "ProviderId                  6\n",
      "ProductId                  23\n",
      "ProductCategory             9\n",
      "ChannelId                   4\n",
      "Amount                   1676\n",
      "Value                    1517\n",
      "TransactionStartTime    94556\n",
      "PricingStrategy             4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Code pour nunique\n",
    "\n",
    "print(\"nunique :\\n\", train.nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous retirons la colonne « transaction_id » en la stockant dans une variable pour poster les données sur le site web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour les garder le transaction_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Le dataset est déjà séparé en training et en validation, ce qui nous épargne cette étape. Afin d’organiser efficacement notre travail, nous rédigeons le code sous forme de pipelines.\n",
    "\n",
    "Nous créons un préprocesseur la transformation des données que nous appliquons au taining set. Ce dernier ne peut pas être appliqué au validation set, cela créerait du data leakage – mais il faut toutefois transformer ces données, d’où l’intérêt de séparer les deux préprocesseurs.\n",
    "Les transformations du premier préprocesseur sont décrites dans le tableau suivant :\n",
    "\n",
    "| Transformateur | Description |\n",
    "| --- | --- |\n",
    "| clean | Pour les colonnes qui ont un id précédé d'un string (par exemple : BatchID_578), retire le texte en ne conserve que le numéro |\n",
    "| amount_to_sign | Remplace les valeurs de la colonne amount par true si elles sont positives et false si elles sont négatives ; la colonne est renommée « sign ». |\n",
    "| day_time_separator | Convertit le format de TransactionStartTime en format yyyymmddhhmmss, et sépare la colonne en jour (TransactionStartDay) et en heure (TransactionStartTime). |\n",
    "| dropper | Supprime les features marqués comme non-pertinents (voir analyse des données) |\n",
    "| one_hot_encode | Effectue un one-hot-encoding pour les colonnes suivantes : ProviderId, ProductCategory, ChannelId, PricingStrategy et Sign. |\n",
    "| weekday | Convertit la colonne TransactionStartDay en jour de la semaine plutôt qu'en date  |\n",
    "| float | Impose le type float sur toutes les colonnes (certaines colonnes du one-hot encoding ne sont plus en float) |\n",
    "| smote | Applique un échantillonnage artificiel sur le dataset. |\n",
    "\n",
    "\n",
    "\n",
    "| shuffle | Randomise l’ordre des entrées dans le dataset. |\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour le pipeline\n",
    "\n",
    "pipeline = imbPipeline(steps = [\n",
    "    (\"clean\", StringCleanTransformer()),\n",
    "    (\"amout to sign\", SignTransformer()),\n",
    "    (\"day_time_separator\", DayTimeTransformer()),\n",
    "    (\"Dropper\", DropperTransformer(drop_cols)),\n",
    "    (\"One hot encoding\", OHTransformer(hot_cols)),\n",
    "    (\"weekday\", weekdayTransformer()),\n",
    "    (\"float\", FloatTransformer()),\n",
    "    (\"smote\", smt),\n",
    "    (\"model\", XGBClassifier(n_estimators = 500))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles\n",
    "Nous entrainons les données adaptées sur trois modèles : un Random Forest, un XGBoost et un MLP ; le tableau suivant montre les performances de ces modèles, sans adaptation particulière de leurs paramètres.\n",
    "\n",
    "Notez que nous faisons initialement une validation croisée sur le training set, qui a tendance à donner des résultats incohérent avec les résultats donnés par le site. Nous ne nous basons donc exlusivement sur le site pour évaluer la qualité de nos modèles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour le modèle de base\n",
    "\n",
    "pipelineRF = imbPipeline(steps = [\n",
    "    (\"clean\", StringCleanTransformer()),\n",
    "    (\"amout to sign\", SignTransformer()),\n",
    "    (\"day_time_separator\", DayTimeTransformer()),\n",
    "    (\"Dropper\", DropperTransformer(drop_cols)),\n",
    "    (\"One hot encoding\", OHTransformer(hot_cols)),\n",
    "    (\"weekday\", weekdayTransformer()),\n",
    "    (\"float\", FloatTransformer()),\n",
    "    (\"smote\", smt),\n",
    "    (\"model\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipelineXGB= imbPipeline(steps = [\n",
    "    (\"clean\", StringCleanTransformer()),\n",
    "    (\"amout to sign\", SignTransformer()),\n",
    "    (\"day_time_separator\", DayTimeTransformer()),\n",
    "    (\"Dropper\", DropperTransformer(drop_cols)),\n",
    "    (\"One hot encoding\", OHTransformer(hot_cols)),\n",
    "    (\"weekday\", weekdayTransformer()),\n",
    "    (\"float\", FloatTransformer()),\n",
    "    (\"smote\", smt),\n",
    "    (\"model\", XGBClassifier())\n",
    "])\n",
    "\n",
    "pipelineMLP= imbPipeline(steps = [\n",
    "    (\"clean\", StringCleanTransformer()),\n",
    "    (\"amout to sign\", SignTransformer()),\n",
    "    (\"day_time_separator\", DayTimeTransformer()),\n",
    "    (\"Dropper\", DropperTransformer(drop_cols)),\n",
    "    (\"One hot encoding\", OHTransformer(hot_cols)),\n",
    "    (\"weekday\", weekdayTransformer()),\n",
    "    (\"float\", FloatTransformer()),\n",
    "    (\"smote\", smt),\n",
    "    (\"model\", MLPClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "for pipeline, name in zip([pipelineRF, pipelineXGB, pipelineMLP],[\"pipelineRF\", \"pipelineXGB\", \"pipelineMLP\"]):\n",
    "    # print(\"cross validation score : \", cross_val_score(pipeline, train, train_Y, cv=5, scoring=\"f1\").mean())\n",
    "    copy_train = train.copy()\n",
    "    copy_train_Y = train_Y.copy()\n",
    "    pipeline.fit(copy_train, copy_train_Y)\n",
    "    test_res = pipeline.predict(test.copy())\n",
    "\n",
    "    output = pd.DataFrame()\n",
    "    output[\"TransactionId\"] = test[\"TransactionId\"]\n",
    "    output[\"FraudResult\"] = test_res\n",
    "\n",
    "    #save the result to csv file\n",
    "    output.to_csv(\"submission\"+name+\".csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont les suivants :\n",
    "\n",
    "| Modèle | Public score | Private score |\n",
    "| --- | --- | --- |\n",
    "| Random Forest | 0.9994 | 0.9994 |\n",
    "| XGBoost | 0.75 | 0.73 |\n",
    "| MLP | 0.9994 | 0.9994 |\n",
    "\n",
    "![Random Forest Result]()\n",
    "![XGBoost Result]()\n",
    "![MLP Result]()\n",
    "\n",
    "Nous voyons clairement que le XGBoost présente les meilleurs résultats. Nous nous tentons donc de partir de cette base pour améliorer encore le modèle. Nous travaillons principalement sur les paramètres suivants  :\n",
    "-\tLe type de booster\n",
    "-\tn_estimators\n",
    "-\tlearning rate\n",
    "-\tmax_depth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour le modèle avec paramètres améliorés"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici les résultats obtenus :\n",
    "\n",
    "| Adaptation | Public score | Private score |\n",
    "| --- | --- | --- |\n",
    "\n",
    "\n",
    "Par ailleurs, nous faisons les essais suivants :\n",
    "-\tEffectuer l’échantillonnage artificiel avant le feature engineering dans le training set\n",
    "-\tConserver le feature « ProductId »"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour le modèle final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion et perspectives\n",
    "[Conclusion]\n",
    "\n",
    "Le score obtenu nous semble satisfaisant, d'autant plus qu'il nous place parmi les 128 meilleurs scores du concours, mais nous pensons qu’il est possible de l’améliorer encore. Nous avons plusieurs pistes pour y parvenir :\n",
    "-\tFaire du binning sur l'heure pour avoir matin - journée - soir au lieu de l'heure exacte.\n",
    "\n",
    "-\tL1 & L2\n",
    "-\tsubsample\n",
    "-\tmin_child_weight\n",
    "-\tgamma\n",
    "\n",
    "-\tFaire davantage de feature engineering avec davantage de domaine knowledge. Au regard des résultats obtenus par les participants au concours, il doit y avoir une manipulation de données qui permet d'améliorer nettement le score, mais à ce stade-ci nous manquons probablement de connaissances spécifiques pour la trouver.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
