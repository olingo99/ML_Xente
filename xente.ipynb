{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/training.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "    for colname in X.select_dtypes([\"object\", \"category\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "    # All discrete features should now have integer dtypes\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "    # f1_scores = cross_val_score(XGBRegressor(), X, y, scoring=\"f1\", cv=5)\n",
    "    # f1_scores = pd.Series(f1_scores, name=\"F1 Scores\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionId</th>\n",
       "      <th>BatchId</th>\n",
       "      <th>AccountId</th>\n",
       "      <th>SubscriptionId</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CurrencyCode</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>ProviderId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ChannelId</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Value</th>\n",
       "      <th>TransactionStartTime</th>\n",
       "      <th>PricingStrategy</th>\n",
       "      <th>FraudResult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TransactionId_76871</td>\n",
       "      <td>BatchId_36123</td>\n",
       "      <td>AccountId_3957</td>\n",
       "      <td>SubscriptionId_887</td>\n",
       "      <td>CustomerId_4406</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_10</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2018-11-15T02:18:49Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TransactionId_73770</td>\n",
       "      <td>BatchId_15642</td>\n",
       "      <td>AccountId_4841</td>\n",
       "      <td>SubscriptionId_3829</td>\n",
       "      <td>CustomerId_4406</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_2</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2018-11-15T02:19:08Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TransactionId_26203</td>\n",
       "      <td>BatchId_53941</td>\n",
       "      <td>AccountId_4229</td>\n",
       "      <td>SubscriptionId_222</td>\n",
       "      <td>CustomerId_4683</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_1</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500</td>\n",
       "      <td>2018-11-15T02:44:21Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TransactionId_380</td>\n",
       "      <td>BatchId_102363</td>\n",
       "      <td>AccountId_648</td>\n",
       "      <td>SubscriptionId_2185</td>\n",
       "      <td>CustomerId_988</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_1</td>\n",
       "      <td>ProductId_21</td>\n",
       "      <td>utility_bill</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>21800</td>\n",
       "      <td>2018-11-15T03:32:55Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TransactionId_28195</td>\n",
       "      <td>BatchId_38780</td>\n",
       "      <td>AccountId_4841</td>\n",
       "      <td>SubscriptionId_3829</td>\n",
       "      <td>CustomerId_988</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_2</td>\n",
       "      <td>-644.0</td>\n",
       "      <td>644</td>\n",
       "      <td>2018-11-15T03:34:21Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TransactionId         BatchId       AccountId       SubscriptionId  \\\n",
       "0  TransactionId_76871   BatchId_36123  AccountId_3957   SubscriptionId_887   \n",
       "1  TransactionId_73770   BatchId_15642  AccountId_4841  SubscriptionId_3829   \n",
       "2  TransactionId_26203   BatchId_53941  AccountId_4229   SubscriptionId_222   \n",
       "3    TransactionId_380  BatchId_102363   AccountId_648  SubscriptionId_2185   \n",
       "4  TransactionId_28195   BatchId_38780  AccountId_4841  SubscriptionId_3829   \n",
       "\n",
       "        CustomerId CurrencyCode  CountryCode    ProviderId     ProductId  \\\n",
       "0  CustomerId_4406          UGX          256  ProviderId_6  ProductId_10   \n",
       "1  CustomerId_4406          UGX          256  ProviderId_4   ProductId_6   \n",
       "2  CustomerId_4683          UGX          256  ProviderId_6   ProductId_1   \n",
       "3   CustomerId_988          UGX          256  ProviderId_1  ProductId_21   \n",
       "4   CustomerId_988          UGX          256  ProviderId_4   ProductId_6   \n",
       "\n",
       "      ProductCategory    ChannelId   Amount  Value  TransactionStartTime  \\\n",
       "0             airtime  ChannelId_3   1000.0   1000  2018-11-15T02:18:49Z   \n",
       "1  financial_services  ChannelId_2    -20.0     20  2018-11-15T02:19:08Z   \n",
       "2             airtime  ChannelId_3    500.0    500  2018-11-15T02:44:21Z   \n",
       "3        utility_bill  ChannelId_3  20000.0  21800  2018-11-15T03:32:55Z   \n",
       "4  financial_services  ChannelId_2   -644.0    644  2018-11-15T03:34:21Z   \n",
       "\n",
       "   PricingStrategy  FraudResult  \n",
       "0                2            0  \n",
       "1                2            0  \n",
       "2                2            0  \n",
       "3                2            0  \n",
       "4                2            0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train.select_dtypes([\"object\"]).nunique()\n",
    "train.head(5)\n",
    "# test.select_dtypes([\"object\"]).nunique()\n",
    "# test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionId           95662\n",
       "BatchId                 94809\n",
       "AccountId                3633\n",
       "SubscriptionId           3627\n",
       "CustomerId               3742\n",
       "CurrencyCode                1\n",
       "CountryCode                 1\n",
       "ProviderId                  6\n",
       "ProductId                  23\n",
       "ProductCategory             9\n",
       "ChannelId                   4\n",
       "Amount                   1676\n",
       "Value                    1517\n",
       "TransactionStartTime    94556\n",
       "PricingStrategy             4\n",
       "FraudResult                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.nunique()\n",
    "# test.nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature encoding and engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "train_Y = train.FraudResult\n",
    "train.drop(['FraudResult'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "features = [\"BatchId\",\"AccountId\",\"SubscriptionId\",\"CustomerId\",\"ProviderId\",\"ProductId\",\"ProductCategory\",\"ChannelId\",\"Amount\",\"Value\",\"TransactionStartTime\",\"PricingStrategy\"]\n",
    "\n",
    "# train.drop(['CurrencyCode','CountryCode'], axis=1, inplace=True)\n",
    "# test.drop(['CurrencyCode','CountryCode'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDay(x):\n",
    "    return float(''.join(x.split(\"T\")[0].split(\"-\")))\n",
    "\n",
    "def getTime(x):\n",
    "    time = x.split(\"T\")[1].split(\":\")\n",
    "    time[-1] = time[-1][:-1]\n",
    "    return float(''.join(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "StringToClean = [\"TransactionId\", \"BatchId\",\"AccountId\",\"SubscriptionId\",\"CustomerId\", \"ProviderId\", \"ProductId\", \"ChannelId\", \"ProductCategory\"]\n",
    "\n",
    "# train[StringToClean].apply()\n",
    "\n",
    "first_data = train.copy()\n",
    "for col in StringToClean:\n",
    "    first_data[col] = first_data[col].apply(lambda x : x.split(\"_\")[-1])\n",
    "\n",
    "first_data[\"TransactionStartDay\"]  = first_data[\"TransactionStartTime\"].apply(getDay)\n",
    "first_data[\"TransactionStartTime\"] = first_data[\"TransactionStartTime\"].apply(getTime)\n",
    "first_data = first_data.set_index(\"TransactionId\")\n",
    "first_data.drop(['CurrencyCode'], axis=1, inplace=True)\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(first_data[\"ProductCategory\"].values.reshape(-1,1)))\n",
    "OH_cols_train.rename(columns=lambda x: \"ProductCategory_\" + str(x), inplace=True)\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = first_data.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = first_data.drop([\"ProductCategory\"], axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "\n",
    "\n",
    "OH_X_train.head()\n",
    "# OH_X_train[\"TransactionStartTime\"].head()\n",
    "train_clean = OH_X_train.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating different models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree = DecisionTreeClassifier()\n",
    "\n",
    "randomForest = RandomForestClassifier()\n",
    "\n",
    "multiLayerPerceptron = MLPClassifier(activation='tanh')\n",
    "\n",
    "# decisionTree.fit(OH_X_train, train_Y)\n",
    "\n",
    "# randomForest.fit(OH_X_train,train_Y)\n",
    "\n",
    "# multiLayerPerceptron.fit(OH_X_train, train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.375      0.42857143 0.54545455 0.61261261 0.34042553]\n"
     ]
    }
   ],
   "source": [
    "f1_scores_mlp = cross_val_score(multiLayerPerceptron, OH_X_train, train_Y, scoring=\"f1\", cv=5)\n",
    "print(f1_scores_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77333333 0.93506494 0.86363636 0.94444444 0.8974359 ]\n"
     ]
    }
   ],
   "source": [
    "f1_scores_DT = cross_val_score(decisionTree, OH_X_train, train_Y, scoring=\"f1\", cv=5)\n",
    "print(f1_scores_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84210526 0.94871795 0.91139241 0.95890411 0.92105263]\n"
     ]
    }
   ],
   "source": [
    "f1_scores_rf = cross_val_score(randomForest, OH_X_train, train_Y, scoring=\"f1\", cv=5)\n",
    "print(f1_scores_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98449451 0.98729212 0.9829031  0.97954422 0.98781513]\n"
     ]
    }
   ],
   "source": [
    "#smote\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "SMOTE = SMOTE()\n",
    "smote_X, smote_Y = SMOTE.fit_resample(OH_X_train, train_Y)\n",
    "\n",
    "# f1_scores_mlp = cross_val_score(multiLayerPerceptron, smote_X, smote_Y, scoring=\"f1\", cv=5)\n",
    "# print(f1_scores_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0    95469\n",
      "1    95469\n",
      "Name: FraudResult, dtype: int64\n",
      "0    95469\n",
      "1      193\n",
      "Name: FraudResult, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(smote_Y.unique())\n",
    "print(smote_Y.value_counts())\n",
    "print(train_Y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BatchId</th>\n",
       "      <th>AccountId</th>\n",
       "      <th>SubscriptionId</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>ProviderId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ChannelId</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Value</th>\n",
       "      <th>...</th>\n",
       "      <th>TransactionStartDay</th>\n",
       "      <th>ProductCategory_0</th>\n",
       "      <th>ProductCategory_1</th>\n",
       "      <th>ProductCategory_2</th>\n",
       "      <th>ProductCategory_3</th>\n",
       "      <th>ProductCategory_4</th>\n",
       "      <th>ProductCategory_5</th>\n",
       "      <th>ProductCategory_6</th>\n",
       "      <th>ProductCategory_7</th>\n",
       "      <th>ProductCategory_8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50600</th>\n",
       "      <td>35028</td>\n",
       "      <td>2441</td>\n",
       "      <td>4426</td>\n",
       "      <td>2857</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>...</td>\n",
       "      <td>20190213.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95109</th>\n",
       "      <td>45139</td>\n",
       "      <td>3439</td>\n",
       "      <td>2643</td>\n",
       "      <td>3874</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>20190213.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47357</th>\n",
       "      <td>74887</td>\n",
       "      <td>4841</td>\n",
       "      <td>3829</td>\n",
       "      <td>2857</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>20190213.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28185</th>\n",
       "      <td>11025</td>\n",
       "      <td>2685</td>\n",
       "      <td>4626</td>\n",
       "      <td>3105</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>...</td>\n",
       "      <td>20190213.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22140</th>\n",
       "      <td>29804</td>\n",
       "      <td>4841</td>\n",
       "      <td>3829</td>\n",
       "      <td>3105</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>20190213.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              BatchId AccountId SubscriptionId CustomerId  CountryCode  \\\n",
       "TransactionId                                                            \n",
       "50600           35028      2441           4426       2857          256   \n",
       "95109           45139      3439           2643       3874          256   \n",
       "47357           74887      4841           3829       2857          256   \n",
       "28185           11025      2685           4626       3105          256   \n",
       "22140           29804      4841           3829       3105          256   \n",
       "\n",
       "              ProviderId ProductId ChannelId  Amount  Value  ...  \\\n",
       "TransactionId                                                ...   \n",
       "50600                  5         3         3  1000.0   1000  ...   \n",
       "95109                  5        15         3  2000.0   2000  ...   \n",
       "47357                  4         6         2   -50.0     50  ...   \n",
       "28185                  5        10         3  3000.0   3000  ...   \n",
       "22140                  4         6         2   -60.0     60  ...   \n",
       "\n",
       "               TransactionStartDay  ProductCategory_0  ProductCategory_1  \\\n",
       "TransactionId                                                              \n",
       "50600                   20190213.0                1.0                0.0   \n",
       "95109                   20190213.0                0.0                0.0   \n",
       "47357                   20190213.0                0.0                0.0   \n",
       "28185                   20190213.0                1.0                0.0   \n",
       "22140                   20190213.0                0.0                0.0   \n",
       "\n",
       "               ProductCategory_2  ProductCategory_3  ProductCategory_4  \\\n",
       "TransactionId                                                            \n",
       "50600                        0.0                0.0                0.0   \n",
       "95109                        0.0                0.0                0.0   \n",
       "47357                        0.0                0.0                0.0   \n",
       "28185                        0.0                0.0                0.0   \n",
       "22140                        0.0                0.0                0.0   \n",
       "\n",
       "               ProductCategory_5  ProductCategory_6  ProductCategory_7  \\\n",
       "TransactionId                                                            \n",
       "50600                        0.0                0.0                0.0   \n",
       "95109                        1.0                0.0                0.0   \n",
       "47357                        1.0                0.0                0.0   \n",
       "28185                        0.0                0.0                0.0   \n",
       "22140                        1.0                0.0                0.0   \n",
       "\n",
       "               ProductCategory_8  \n",
       "TransactionId                     \n",
       "50600                        0.0  \n",
       "95109                        0.0  \n",
       "47357                        0.0  \n",
       "28185                        0.0  \n",
       "22140                        0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StringToClean = [\"TransactionId\", \"BatchId\",\"AccountId\",\"SubscriptionId\",\"CustomerId\", \"ProviderId\", \"ProductId\", \"ChannelId\", \"ProductCategory\"]\n",
    "\n",
    "# train[StringToClean].apply()\n",
    "\n",
    "test_data = test.copy()\n",
    "for col in StringToClean:\n",
    "    test_data[col] = test_data[col].apply(lambda x : x.split(\"_\")[-1])\n",
    "\n",
    "test_data[\"TransactionStartDay\"]  = test_data[\"TransactionStartTime\"].apply(getDay)\n",
    "test_data[\"TransactionStartTime\"] = test_data[\"TransactionStartTime\"].apply(getTime)\n",
    "test_data = test_data.set_index(\"TransactionId\")\n",
    "test_data.drop(['CurrencyCode'], axis=1, inplace=True)\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(test_data[\"ProductCategory\"].values.reshape(-1,1)))\n",
    "OH_cols_train.rename(columns=lambda x: \"ProductCategory_\" + str(x), inplace=True)\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = test_data.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = test_data.drop([\"ProductCategory\"], axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "\n",
    "\n",
    "OH_X_train.head()\n",
    "# OH_X_train[\"TransactionStartTime\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiLayerPerceptron.fit(smote_X, smote_Y)\n",
    "test_res = multiLayerPerceptron.predict(OH_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree.fit(smote_X, smote_Y)\n",
    "test_res = decisionTree.predict(OH_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest.fit(smote_X, smote_Y)\n",
    "test_res = randomForest.predict(OH_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "my_model = XGBClassifier(n_estimators=500)\n",
    "#change dtype of all collumns to float\n",
    "X = smote_X.astype('float32')\n",
    "Y = smote_Y.astype('float32')\n",
    "my_model.fit(X,Y)\n",
    "test_res = my_model.predict(OH_X_train.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([44936,    83], dtype=int64))\n",
      "(array([0, 1], dtype=int64), array([44338,   681], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "a = my_model.predict(OH_X_train.astype('float32'))\n",
    "b = multiLayerPerceptron.predict(OH_X_train)\n",
    "\n",
    "print(np.unique(a, return_counts=True))\n",
    "print(np.unique(b, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "           TransactionId  FraudResult\n",
      "0    TransactionId_50600            0\n",
      "1    TransactionId_95109            0\n",
      "2    TransactionId_47357            0\n",
      "3    TransactionId_28185            0\n",
      "4    TransactionId_22140            0\n",
      "5   TransactionId_134338            0\n",
      "6   TransactionId_109096            0\n",
      "7    TransactionId_14249            0\n",
      "8    TransactionId_69896            0\n",
      "9    TransactionId_91468            0\n",
      "10   TransactionId_18862            0\n",
      "11   TransactionId_29342            0\n",
      "12  TransactionId_116873            0\n",
      "13   TransactionId_81197            0\n",
      "14   TransactionId_83120            0\n",
      "15   TransactionId_40882            0\n",
      "16   TransactionId_89297            0\n",
      "17  TransactionId_112716            0\n",
      "18   TransactionId_61794            0\n",
      "19  TransactionId_124957            0\n"
     ]
    }
   ],
   "source": [
    "print(test_res)\n",
    "\n",
    "#concatenate the test result with coresponding transaction id\n",
    "output = pd.DataFrame()\n",
    "output[\"TransactionId\"] = test[\"TransactionId\"]\n",
    "output[\"FraudResult\"] = test_res\n",
    "print(output.head(20))\n",
    "\n",
    "#save the result to csv file\n",
    "output.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BatchId</th>\n",
       "      <th>AccountId</th>\n",
       "      <th>SubscriptionId</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>ProviderId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ChannelId</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Value</th>\n",
       "      <th>...</th>\n",
       "      <th>TransactionStartDay</th>\n",
       "      <th>ProductCategory_0</th>\n",
       "      <th>ProductCategory_1</th>\n",
       "      <th>ProductCategory_2</th>\n",
       "      <th>ProductCategory_3</th>\n",
       "      <th>ProductCategory_4</th>\n",
       "      <th>ProductCategory_5</th>\n",
       "      <th>ProductCategory_6</th>\n",
       "      <th>ProductCategory_7</th>\n",
       "      <th>ProductCategory_8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130102</th>\n",
       "      <td>33496</td>\n",
       "      <td>4841</td>\n",
       "      <td>3829</td>\n",
       "      <td>2528</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>20181231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133204</th>\n",
       "      <td>16672</td>\n",
       "      <td>4389</td>\n",
       "      <td>4791</td>\n",
       "      <td>4846</td>\n",
       "      <td>256</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500</td>\n",
       "      <td>...</td>\n",
       "      <td>20181126.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104728</th>\n",
       "      <td>137854</td>\n",
       "      <td>4249</td>\n",
       "      <td>4429</td>\n",
       "      <td>7343</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>-10000.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>...</td>\n",
       "      <td>20190108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90921</th>\n",
       "      <td>68518</td>\n",
       "      <td>769</td>\n",
       "      <td>4636</td>\n",
       "      <td>1114</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1800</td>\n",
       "      <td>...</td>\n",
       "      <td>20181220.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56303</th>\n",
       "      <td>67763</td>\n",
       "      <td>2441</td>\n",
       "      <td>4426</td>\n",
       "      <td>2857</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>...</td>\n",
       "      <td>20190112.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              BatchId AccountId SubscriptionId CustomerId  CountryCode  \\\n",
       "TransactionId                                                            \n",
       "130102          33496      4841           3829       2528          256   \n",
       "133204          16672      4389           4791       4846          256   \n",
       "104728         137854      4249           4429       7343          256   \n",
       "90921           68518       769           4636       1114          256   \n",
       "56303           67763      2441           4426       2857          256   \n",
       "\n",
       "              ProviderId ProductId ChannelId   Amount  Value  ...  \\\n",
       "TransactionId                                                 ...   \n",
       "130102                 4         6         2    -20.0     20  ...   \n",
       "133204                 6         3         3    500.0    500  ...   \n",
       "104728                 4        10         2 -10000.0  10000  ...   \n",
       "90921                  5         3         3   1800.0   1800  ...   \n",
       "56303                  5         3         3   3000.0   3000  ...   \n",
       "\n",
       "               TransactionStartDay  ProductCategory_0  ProductCategory_1  \\\n",
       "TransactionId                                                              \n",
       "130102                  20181231.0                0.0                0.0   \n",
       "133204                  20181126.0                1.0                0.0   \n",
       "104728                  20190108.0                1.0                0.0   \n",
       "90921                   20181220.0                1.0                0.0   \n",
       "56303                   20190112.0                1.0                0.0   \n",
       "\n",
       "               ProductCategory_2  ProductCategory_3  ProductCategory_4  \\\n",
       "TransactionId                                                            \n",
       "130102                       0.0                0.0                0.0   \n",
       "133204                       0.0                0.0                0.0   \n",
       "104728                       0.0                0.0                0.0   \n",
       "90921                        0.0                0.0                0.0   \n",
       "56303                        0.0                0.0                0.0   \n",
       "\n",
       "               ProductCategory_5  ProductCategory_6  ProductCategory_7  \\\n",
       "TransactionId                                                            \n",
       "130102                       1.0                0.0                0.0   \n",
       "133204                       0.0                0.0                0.0   \n",
       "104728                       0.0                0.0                0.0   \n",
       "90921                        0.0                0.0                0.0   \n",
       "56303                        0.0                0.0                0.0   \n",
       "\n",
       "               ProductCategory_8  \n",
       "TransactionId                     \n",
       "130102                       0.0  \n",
       "133204                       0.0  \n",
       "104728                       0.0  \n",
       "90921                        0.0  \n",
       "56303                        0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for colname in train_clean.select_dtypes(\"object\"):\n",
    "#     train_clean[colname], _ =train_clean[colname].factorize()\n",
    "\n",
    "train_clean.head()\n",
    "train_clean.select_dtypes(\"object\").head()\n",
    "\n",
    "scores = make_mi_scores(train_clean, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchId                 0.112173\n",
      "Value                   0.016750\n",
      "CustomerId              0.010575\n",
      "SubscriptionId          0.007633\n",
      "AccountId               0.007132\n",
      "ProductCategory_8       0.004976\n",
      "ProviderId              0.003615\n",
      "ProductId               0.003456\n",
      "ProductCategory_0       0.003270\n",
      "ChannelId               0.001853\n",
      "ProductCategory_5       0.001193\n",
      "TransactionStartDay     0.001054\n",
      "ProductCategory_6       0.000858\n",
      "TransactionStartTime    0.000628\n",
      "PricingStrategy         0.000560\n",
      "ProductCategory_2       0.000525\n",
      "CountryCode             0.000010\n",
      "ProductCategory_1       0.000000\n",
      "ProductCategory_3       0.000000\n",
      "ProductCategory_4       0.000000\n",
      "ProductCategory_7       0.000000\n",
      "Sign                    0.000000\n",
      "Name: MI Scores, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "train_clean[\"Sign\"] = train_clean[\"Amount\"].apply(lambda x : x>=0)\n",
    "train_clean.drop([\"Amount\"], axis=1, inplace=True)\n",
    "train_clean.drop([\"CountryCode\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchId                  object\n",
      "AccountId                object\n",
      "SubscriptionId           object\n",
      "CustomerId               object\n",
      "CountryCode               int64\n",
      "ProviderId               object\n",
      "ProductId                object\n",
      "ChannelId                object\n",
      "Value                     int64\n",
      "TransactionStartTime    float64\n",
      "PricingStrategy           int64\n",
      "TransactionStartDay     float64\n",
      "ProductCategory_0       float64\n",
      "ProductCategory_1       float64\n",
      "ProductCategory_2       float64\n",
      "ProductCategory_3       float64\n",
      "ProductCategory_4       float64\n",
      "ProductCategory_5       float64\n",
      "ProductCategory_6       float64\n",
      "ProductCategory_7       float64\n",
      "ProductCategory_8       float64\n",
      "Sign                       bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_clean.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\engel\\Documents\\4MIN\\MachineLeanring\\Xente\\ML_Xente\\xente.ipynb Cell 33\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/engel/Documents/4MIN/MachineLeanring/Xente/ML_Xente/xente.ipynb#X44sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     loadings \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/engel/Documents/4MIN/MachineLeanring/Xente/ML_Xente/xente.ipynb#X44sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         pca\u001b[39m.\u001b[39mcomponents_\u001b[39m.\u001b[39mT,  \u001b[39m# transpose the matrix of loadings\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/engel/Documents/4MIN/MachineLeanring/Xente/ML_Xente/xente.ipynb#X44sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         columns\u001b[39m=\u001b[39mcomponent_names,  \u001b[39m# so the columns are the principal components\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/engel/Documents/4MIN/MachineLeanring/Xente/ML_Xente/xente.ipynb#X44sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         index\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mcolumns,  \u001b[39m# and the rows are the original features\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/engel/Documents/4MIN/MachineLeanring/Xente/ML_Xente/xente.ipynb#X44sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/engel/Documents/4MIN/MachineLeanring/Xente/ML_Xente/xente.ipynb#X44sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m pca, X_pca, loadings\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/engel/Documents/4MIN/MachineLeanring/Xente/ML_Xente/xente.ipynb#X44sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m pca, X_pca, loadings \u001b[39m=\u001b[39m apply_pca(train_clean\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m), standardize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/engel/Documents/4MIN/MachineLeanring/Xente/ML_Xente/xente.ipynb#X44sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(loadings)\n",
      "\u001b[1;32mc:\\Users\\engel\\Documents\\4MIN\\MachineLeanring\\Xente\\ML_Xente\\xente.ipynb Cell 33\u001b[0m in \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/engel/Documents/4MIN/MachineLeanring/Xente/ML_Xente/xente.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Create principal components\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/engel/Documents/4MIN/MachineLeanring/Xente/ML_Xente/xente.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m pca \u001b[39m=\u001b[39m PCA()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/engel/Documents/4MIN/MachineLeanring/Xente/ML_Xente/xente.ipynb#X44sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m X_pca \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/engel/Documents/4MIN/MachineLeanring/Xente/ML_Xente/xente.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Convert to dataframe\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/engel/Documents/4MIN/MachineLeanring/Xente/ML_Xente/xente.ipynb#X44sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m component_names \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPC\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(X_pca\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])]\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:462\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \n\u001b[0;32m    441\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mC-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 462\u001b[0m U, S, Vt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[0;32m    463\u001b[0m U \u001b[39m=\u001b[39m U[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components_]\n\u001b[0;32m    465\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhiten:\n\u001b[0;32m    466\u001b[0m     \u001b[39m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:485\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    480\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m     )\n\u001b[1;32m--> 485\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    486\u001b[0m     X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    487\u001b[0m )\n\u001b[0;32m    489\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[0;32m    922\u001b[0m             array,\n\u001b[0;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    926\u001b[0m         )\n\u001b[0;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def apply_pca(X, standardize=True):\n",
    "    # Standardize\n",
    "    if standardize:\n",
    "        X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    # Create principal components\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    # Convert to dataframe\n",
    "    component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "    X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
    "    # Create loadings\n",
    "    loadings = pd.DataFrame(\n",
    "        pca.components_.T,  # transpose the matrix of loadings\n",
    "        columns=component_names,  # so the columns are the principal components\n",
    "        index=X.columns,  # and the rows are the original features\n",
    "    )\n",
    "    return pca, X_pca, loadings\n",
    "\n",
    "\n",
    "pca, X_pca, loadings = apply_pca(train_clean.astype('float32'), standardize=True)\n",
    "print(loadings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
